# Copyright 2022 OmniSafe Team. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

defaults:
  # --------------------------------------Basic Configurations----------------------------------- #
  ## -----------------------------Basic configurations for Vae behaviour clone------------------------ ##
  # The random seed
  seed: 0
  # The environment wrapper type
  wrapper_type: OfflineEnvWrapper
  # Number of epochs
  epochs: 1000
  # Reward discounted factor
  gamma: 1.0
  # Number of grad steps per epoch
  grad_steps_per_epoch: 1000
  # Number of batch sizes
  batch_size: 256
  # Save model to disk
  save_freq: 100
  # Number of epoisodes to run when evaluate
  eval_episodes: 30
  # CUDA or CPU device
  device: 'cuda:0'
  # The Address for saving training process data
  data_dir: './runs/offline'
  # The path of dataset
  dataset_path: './runs/data/SafetyPointCircle0-v0-mixed-std02.npz'
  ## ---------------------------------------Configuration For Model----------------------------- ##
  model_cfgs:
    # The mode to initiate the weight of network, choosing from "kaiming_uniform", "xavier_normal", "glorot" and "orthogonal".
    weight_initialization_mode: "kaiming_uniform"
    # Configuration of Actor network
    actor_cfgs:
      # Size of hidden layers
      hidden_sizes: [256, 256, 256]
      # Type of activation functon, choosing from "tanh", "relu", "sigmoid", "identity", "softplus"
      activation: relu
    # Configuration of Nu network
    nu_net_cfgs:
      # Size of hidden layers
      hidden_sizes: [256, 256, 256]
      # Type of activation functon, choosing from "tanh", "relu", "sigmoid", "identity", "softplus"
      activation: relu
    # Configuration of Chi network
    chi_net_cfgs:
      # Size of hidden layers
      hidden_sizes: [256, 256, 256]
      # Type of activation functon, choosing from "tanh", "relu", "sigmoid", "identity", "softplus"
      activation: relu
  # The learning rate of Actor network
  actor_lr: 0.0003
  # The learning rate of Nu network
  nu_net_lr: 0.0003
  # The learning rate of chi network
  chi_net_lr: 0.0003
  # Initial value of lagrangian multiplier
  lamb_init: 0
  # Type of lagrangian optimizer
  lamb_optimizer: "Adam"
  # Learning rate of lagrangian multiplier
  lamb_lr: 0.035
  # Initial value of tau multiplier
  tau_init: 1
  # Type of tau optimizer
  tau_optimizer: "Adam"
  # Learning rate of tau multiplier
  tau_lr: 0.0003
  # The type of f-divergence function
  fn_type: softchi
  # Regularizer on Df(d|dD).
  alpha: 0.01
  # Adjusts the degree of overestimation of cost value.
  cost_ub_eps: 0.01
  # Tolerance of constraint violation
  cost_limit: 0.06
